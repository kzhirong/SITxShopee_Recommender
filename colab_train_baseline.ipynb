{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Baseline DeepFM on Google Colab\n",
    "\n",
    "This notebook trains the baseline DeepFM model on normalized Avazu x4 dataset.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Upload this notebook to Google Colab\n",
    "2. Runtime > Change runtime type > GPU (T4 GPU recommended)\n",
    "3. Run all cells in order\n",
    "\n",
    "## What this does:\n",
    "- Clones your GitHub repository\n",
    "- Installs dependencies\n",
    "- Downloads normalized Avazu x4 dataset (or uses uploaded data)\n",
    "- Trains DeepFM baseline model\n",
    "- Downloads the trained checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected. Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository (Option A) or Upload Files (Option B)\n",
    "\n",
    "### Option A: Clone from GitHub (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/YOUR_USERNAME/SITxShopee_Recommender.git\n",
    "%cd SITxShopee_Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Upload as ZIP file\n",
    "\n",
    "If your repo is private or you prefer to upload:\n",
    "1. Zip your entire project folder (exclude `data/` directory - too large)\n",
    "2. Upload the ZIP file using the file browser on the left\n",
    "3. Run the cell below to extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using ZIP upload method\n",
    "# !unzip SITxShopee_Recommender.zip\n",
    "# %cd SITxShopee_Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q scikit-learn pandas numpy pyyaml h5py tqdm transformers\n",
    "\n",
    "# Verify installation\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "print(\"✓ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Dataset\n",
    "\n",
    "### Option A: Download from Google Drive (Recommended)\n",
    "\n",
    "**Before running Colab**: Upload your normalized dataset to Google Drive\n",
    "1. Compress `data/Avazu/avazu_x4_normalized/` into a ZIP file\n",
    "2. Upload to Google Drive\n",
    "3. Get shareable link and extract file ID\n",
    "4. Replace FILE_ID below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Option A1: If dataset is in your Google Drive\n",
    "# Copy from Drive to Colab workspace\n",
    "!mkdir -p data/Avazu/\n",
    "!cp -r \"/content/drive/MyDrive/avazu_x4_normalized\" data/Avazu/\n",
    "\n",
    "# Verify\n",
    "!ls -lh data/Avazu/avazu_x4_normalized/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Download from URL\n",
    "\n",
    "If you have the dataset hosted somewhere (e.g., Dropbox, Google Drive public link):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify if downloading from URL\n",
    "# !mkdir -p data/Avazu/\n",
    "# !wget -O avazu_x4_normalized.zip \"YOUR_DOWNLOAD_URL_HERE\"\n",
    "# !unzip avazu_x4_normalized.zip -d data/Avazu/\n",
    "# !rm avazu_x4_normalized.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Run normalization script on Colab\n",
    "\n",
    "Download raw data and normalize on Colab (takes longer but works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download and normalize on Colab\n",
    "# !bash 1.prepare.sh  # Download raw Avazu datasets\n",
    "# !python normalize_avazu_datasets.py  # Normalize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything is ready\n",
    "import os\n",
    "\n",
    "checks = [\n",
    "    (\"FuxiCTR framework\", os.path.exists(\"fuxictr\")),\n",
    "    (\"DeepFM model\", os.path.exists(\"model_zoo/DeepFM/src/DeepFM.py\")),\n",
    "    (\"Model config\", os.path.exists(\"model_zoo/DeepFM/config/model_config.yaml\")),\n",
    "    (\"Dataset config\", os.path.exists(\"model_zoo/DeepFM/config/dataset_config.yaml\")),\n",
    "    (\"Training data\", os.path.exists(\"data/Avazu/avazu_x4_normalized/train.csv\")),\n",
    "    (\"Validation data\", os.path.exists(\"data/Avazu/avazu_x4_normalized/valid.csv\")),\n",
    "    (\"Test data\", os.path.exists(\"data/Avazu/avazu_x4_normalized/test.csv\")),\n",
    "]\n",
    "\n",
    "all_ready = True\n",
    "for name, exists in checks:\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {name}\")\n",
    "    if not exists:\n",
    "        all_ready = False\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\n✅ All checks passed! Ready to train.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Some files are missing. Please check above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Start Training\n",
    "\n",
    "This will train for 100 epochs. You can reduce epochs in the config if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python model_zoo/DeepFM/run_expid.py \\\n",
    "    --expid DeepFM_avazu_normalized \\\n",
    "    --gpu 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List checkpoint files\n",
    "!find model_zoo/DeepFM/Avazu/DeepFM_avazu_normalized/ -type f\n",
    "\n",
    "# Show training log summary\n",
    "!tail -50 model_zoo/DeepFM/Avazu/DeepFM_avazu_normalized/*/DeepFM_avazu_normalized.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Download Checkpoint to Your Computer\n",
    "\n",
    "Compress and download the trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress checkpoint directory\n",
    "!cd model_zoo/DeepFM/Avazu/DeepFM_avazu_normalized/ && \\\n",
    "    tar -czf /content/checkpoint_baseline.tar.gz .\n",
    "\n",
    "print(\"✓ Checkpoint compressed to: /content/checkpoint_baseline.tar.gz\")\n",
    "print(\"\\nDownload it using the file browser on the left, or:\")\n",
    "\n",
    "# Download via Colab files API\n",
    "from google.colab import files\n",
    "files.download('/content/checkpoint_baseline.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save to Google Drive (Optional)\n",
    "\n",
    "Save checkpoint to your Google Drive for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy checkpoint to Google Drive\n",
    "!cp /content/checkpoint_baseline.tar.gz \"/content/drive/MyDrive/\"\n",
    "print(\"✓ Checkpoint saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "### Expected Training Time:\n",
    "- **With T4 GPU**: ~4-6 hours for 100 epochs on Avazu x4\n",
    "- **With CPU**: Very slow (not recommended)\n",
    "\n",
    "### To Reduce Training Time:\n",
    "Edit `model_zoo/DeepFM/config/model_config.yaml` and change:\n",
    "```yaml\n",
    "DeepFM_avazu_normalized:\n",
    "    epochs: 20  # Reduced from 100\n",
    "```\n",
    "\n",
    "### Monitoring Training:\n",
    "Watch the AUC and logloss metrics. Training is working if:\n",
    "- AUC increases over epochs\n",
    "- Logloss decreases over epochs\n",
    "\n",
    "### After Training:\n",
    "1. Download the checkpoint\n",
    "2. Extract on your local machine: `tar -xzf checkpoint_baseline.tar.gz`\n",
    "3. Place in: `model_zoo/DeepFM/Avazu/DeepFM_avazu_normalized/`\n",
    "4. Ready for Phase 2 (LLM-CTR training)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
